# Point Cloud Backbone

- PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies. [[Paper]](https://arxiv.org/abs/2206.04670)![Static Badge](https://img.shields.io/badge/NeurIPS-%202022-blue)

- Masked Autoencoders for Point Cloud Self-supervised Learning. [[Paper]](https://link.springer.com/chapter/10.1007/978-3-031-20086-1_35)![Static Badge](https://img.shields.io/badge/ECCV-%202022-blue)

- Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding. [[Paper]](https://arxiv.org/abs/2304.06906)![Static Badge](https://img.shields.io/badge/arxiv%202304-red)

- Point Transformer V3: Simpler, Faster, Stronger. [[Paper]](https://arxiv.org/abs/2312.10035)![Static Badge](https://img.shields.io/badge/CVPR-%202024-blue)

- ShapeSplat: A Large-scale Dataset of Gaussian Splats and Their Self-Supervised Pretraining. [[Paper]](https://arxiv.org/abs/2408.10906)![Static Badge](https://img.shields.io/badge/arxiv%202408-red)

- MAP: Unleashing Hybrid Mamba-Transformer Vision Backboneâ€™s Potential with Masked Autoregressive Pretraining. [[Paper]](https://arxiv.org/abs/2410.00871)![Static Badge](https://img.shields.io/badge/arxiv%202410-red)

- Point Cloud Understanding via Attention-Driven Contrastive Learning. [[Paper]](https://arxiv.org/abs/2411.14744)![Static Badge](https://img.shields.io/badge/arxiv%202411-red)

- Point Cloud Unsupervised Pre-training via 3D Gaussian Splatting. [[Paper]](https://arxiv.org/abs/2411.18667)![Static Badge](https://img.shields.io/badge/arxiv%202411-red)

- ......
