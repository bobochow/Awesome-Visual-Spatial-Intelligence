# Embodied-Spatial Intelligence

## Related Resource

- [Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide)  ![Stars](https://img.shields.io/github/stars/TianxingChen/Embodied-AI-Guide?style=social) ![Last Commit](https://img.shields.io/github/last-commit/TianxingChen/Embodied-AI-Guide)

- [awesome-embodied-vla-va-vln](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln) ![Stars](https://img.shields.io/github/stars/jonyzhang2023/awesome-embodied-vla-va-vln?style=social) ![Last Commit](https://img.shields.io/github/last-commit/jonyzhang2023/awesome-embodied-vla-va-vln)

- [Embodied_AI_Paper_List](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List) ![Stars](https://img.shields.io/github/stars/HCPLab-SYSU/Embodied_AI_Paper_List?style=social) ![Last Commit](https://img.shields.io/github/last-commit/HCPLab-SYSU/Embodied_AI_Paper_List)

- [Awesome-Embodied-Robotics-and-Agent](https://github.com/zchoi/Awesome-Embodied-Robotics-and-Agent) ![Stars](https://img.shields.io/github/stars/zchoi/Awesome-Embodied-Robotics-and-Agent?style=social) ![Last Commit](https://img.shields.io/github/last-commit/zchoi/Awesome-Embodied-Robotics-and-Agent)

## Survey

- A Survey on Vision-Language-Action Models for Embodied AI [[Paper](https://arxiv.org/abs/2405.14093)]![Static Badge](https://img.shields.io/badge/arXiv%202405-red)

- Vision-Language Navigation with Embodied Intelligence: A Survey [[Paper](https://arxiv.org/abs/2402.14304)]![Static Badge](https://img.shields.io/badge/arXiv%202402-red)


## List

- SUGAR: Pre-training 3D Visual Representations for Robotics [[Paper](https://arxiv.org/abs/2404.01491)]![Static Badge](https://img.shields.io/badge/CVPR%202024-blue)

- Point Cloud Matters: Rethinking the Impact of Different Observation Spaces on Robot Learning [[Paper](https://arxiv.org/abs/2402.02500)]![Static Badge](https://img.shields.io/badge/NeurIPS%202024-blue)

- Spatiotemporal Predictive Pre-training for Robotic Motor Control [[Paper](https://arxiv.org/abs/2403.05304)]![Static Badge](https://img.shields.io/badge/arXiv%202403-red)

- Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation [[Paper](https://arxiv.org/abs/2411.18623)]![Static Badge](https://img.shields.io/badge/arXiv%202411-red)

- FusionSense: Bridging Common Sense, Vision, and Touch for Robust Sparse-View Reconstruction [[Paper](https://arxiv.org/abs/2410.08282)]![Static Badge](https://img.shields.io/badge/arXiv%202410-red)

- ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation [[Paper](https://arxiv.org/abs/2409.01652)]![Static Badge](https://img.shields.io/badge/CoRL%202024-blue)


- RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics [[Paper](https://arxiv.org/abs/2411.16537)]![Static Badge](https://img.shields.io/badge/arXiv%202411-red)

- Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Dataset [[Paper](https://arxiv.org/abs/2410.22325)]![Static Badge](https://img.shields.io/badge/ICLR%202025-blue)

- RLS3: RL-Based Synthetic Sample Selection to Enhance Spatial Reasoning in Vision-Language Models for Indoor Autonomous Perception [[Paper](https://arxiv.org/abs/2501.18880)]![Static Badge](https://img.shields.io/badge/arXiv%202501-red)

- SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation [[Paper](https://arxiv.org/abs/2502.13143)]![Static Badge](https://img.shields.io/badge/arXiv%202502-red)

- Spatially Visual Perception for End-to-End Robotic Learning [[Paper](https://arxiv.org/abs/2411.17458)]![Static Badge](https://img.shields.io/badge/arXiv%202411-red)

- SpatialVLA: Exploring Spatial Representations for Visual-Language-Action Model [[Paper](https://arxiv.org/abs/2501.15830)]![Static Badge](https://img.shields.io/badge/arXiv%202501-red)

- ......


