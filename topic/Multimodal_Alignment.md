# Multimodal Alignment

## Related Resource

- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) ![Stars](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models?style=social) ![Last Commit](https://img.shields.io/github/last-commit/BradyFU/Awesome-Multimodal-Large-Language-Models)

- [Awesome-Multimodal-Research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research) ![Stars](https://img.shields.io/github/stars/Eurus-Holmes/Awesome-Multimodal-Research?style=social) ![Last Commit](https://img.shields.io/github/last-commit/Eurus-Holmes/Awesome-Multimodal-Research)

- [Awesome-Multimodal-ML](https://github.com/pliang279/awesome-multimodal-ml) ![Stars](https://img.shields.io/github/stars/pliang279/awesome-multimodal-ml?style=social) ![Last Commit](https://img.shields.io/github/last-commit/pliang279/awesome-multimodal-ml)

- [Awesome-RL-based-Reasoning-MLLMs](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs) ![Stars](https://img.shields.io/github/stars/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs?style=social) ![Last Commit](https://img.shields.io/github/last-commit/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs)

## Survey

- Aligning Multimodal LLM with Human Preference: A Survey [[Paper](https://arxiv.org/abs/2503.14504)] ![Static Badge](https://img.shields.io/badge/arXiv%202503-red)

## List

- ImageBind: One Embedding Space to Bind Them All [[Paper](https://arxiv.org/abs/2305.01877)] ![Static Badge](https://img.shields.io/badge/CVPR%202023-blue)
- ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities [[Paper](https://arxiv.org/abs/2305.11172)] ![Static Badge](https://img.shields.io/badge/arXiv%202305-red)
- Audioclip: Extending Clip to Image, Text and Audio [[Paper](https://doi.org/10.1109/ICASSP43922.2022.9747631)] ![Static Badge](https://img.shields.io/badge/ICASSP%202022-blue)
- TULIP: Towards Unified Language-Image Pretraining [[Paper](https://arxiv.org/abs/2503.15485)] ![Static Badge](https://img.shields.io/badge/CVPR%202025-blue)
- Alt-MoE: Multimodal Alignment via Alternating Optimization of Multi-directional MoE with Unimodal Models [[Paper](https://arxiv.org/abs/2409.05929)] ![Static Badge](https://img.shields.io/badge/arXiv%202409-red)
- X²-VLM: All-in-One Pre-Trained Model for Vision-Language Tasks [[Paper](https://doi.org/10.1109/TPAMI.2023.3339661)] ![Static Badge](https://img.shields.io/badge/TPAMI-green)
- Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs [[Paper](https://arxiv.org/abs/2405.16700)] ![Static Badge](https://img.shields.io/badge/NeurIPS%202024-blue)
- PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining [[Paper](https://arxiv.org/abs/2204.14095)] ![Static Badge](https://img.shields.io/badge/NeurIPS%202022-blue)
- Assessing and Learning Alignment of Unimodal Vision and Language Models [[Paper](https://arxiv.org/abs/2412.04616)] ![Static Badge](https://img.shields.io/badge/arXiv%202412-red)
- AlignMamba: Enhancing Multimodal Mamba with Local and Global Cross-modal Alignment [[Paper](https://arxiv.org/abs/2412.00833)] ![Static Badge](https://img.shields.io/badge/arXiv%202412-red)
- Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback [[Paper](https://arxiv.org/abs/2412.15838)] ![Static Badge](https://img.shields.io/badge/arXiv%202412-red)
- Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment [[Paper](https://arxiv.org/abs/2412.19326)] ![Static Badge](https://img.shields.io/badge/arXiv%202412-red)
- Context-Based Semantic-Aware Alignment for Semi-Supervised Multi-Label Learning [[Paper](https://arxiv.org/abs/2412.18842)] ![Static Badge](https://img.shields.io/badge/arXiv%202412-red)
- Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion [[Paper](https://arxiv.org/abs/2502.04263)] ![Static Badge](https://img.shields.io/badge/ICLR%202025-blue)
- Universal Sparse Autoencoders: Interpretable Cross-Model Concept Alignment [[Paper](https://arxiv.org/abs/2502.03714)] ![Static Badge](https://img.shields.io/badge/arXiv%202502-red)
- Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization [[Paper](https://arxiv.org/abs/2502.13146)] ![Static Badge](https://img.shields.io/badge/arXiv%202502-red)
- CrossOver: 3D Scene Cross-Modal Alignment [[Paper](https://arxiv.org/abs/2502.15011)] ![Static Badge](https://img.shields.io/badge/arXiv%202502-red)
- Escaping Plato’s Cave: Towards the Alignment of 3D and Text Latent Spaces [[Paper](https://arxiv.org/abs/2503.05283)] ![Static Badge](https://img.shields.io/badge/arXiv%202503-red)

- ......
